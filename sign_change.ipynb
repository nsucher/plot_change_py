{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88e06506-4984-4626-9860-6ffc5ffc8df7",
   "metadata": {},
   "source": [
    "sign_change.py: Generate positive or negative average weight changes at each electrode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440d16a1-af04-48fb-a299-6577a6697063",
   "metadata": {},
   "source": [
    "## Pseudocode:\n",
    "    . Import\n",
    "    . Input symptom, mode, perdur\n",
    "    . Define functions\n",
    "    . For Loop through seizures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0a6cc7-830d-4219-9ea4-de99aa7f2d08",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fd52eb6-be5b-4151-8ea1-4e3a9c153ac6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import pathlib\n",
    "import xlsxwriter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.io import loadmat\n",
    "from scipy.signal import butter,filtfilt\n",
    "from scipy.stats import ttest_1samp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19eca60b-2e93-4c30-ba16-e35db39abb42",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Input symptom, mode, and duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f231bde-295d-47fa-9cf0-b54537936282",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "neuroanat_list = ['frontalpole', #FRONTAL LOBE\n",
    "    'parstriangularis',\n",
    "    'parsopercularis',\n",
    "    'parsorbitalis',\n",
    "    'rostralmiddlefrontal',\n",
    "    'caudalmiddlefrontal',\n",
    "    'lateralorbitofrontal',\n",
    "    'superiorfrontal',\n",
    "    'medialorbitofrontal',\n",
    "    'precentral',\n",
    "    'postcentral', # PARIETAL LOBE\n",
    "    'inferiorparietal',   \n",
    "    'superiorparietal',\n",
    "    'supramarginal',\n",
    "    'temporalpole', # TEMPORAL LOBE\n",
    "    'middletemporal',\n",
    "    'superiortemporal',\n",
    "    'inferiortemporal',\n",
    "    'parahippocampal',               \n",
    "    'Right-Hippocampus',\n",
    "    'Left-Hippocampus',\n",
    "    'Right-Amygdala',\n",
    "    'Left-Amygdala',\n",
    "    'entorhinal',\n",
    "    'bankssts',\n",
    "    'fusiform', # OCCIPITAL LOBE                \n",
    "    'lingual']\n",
    "    # 'Right-Inf-Lat-Vent', # OTHER\n",
    "    # 'Right-Cerebral-White-Matter',\n",
    "    # 'Left-Cerebral-White-Matter',\n",
    "    # 'Right-choroid-plexus',\n",
    "    # 'Right-Putamen',\n",
    "    # 'Right-VentralDC'];\n",
    "    \n",
    "abv_neuroanat_list = ['front-pole', #FRONTAL LOBE\n",
    "    'parstri',\n",
    "    'parsop',\n",
    "    'parsorb',\n",
    "    'rost-midfront',\n",
    "    'caud-midfront',\n",
    "    'latorb-front',\n",
    "    'sup-front',\n",
    "    'medorb-front',\n",
    "    'precentral',\n",
    "    'postcentral', # PARIETAL LOBE\n",
    "    'inf-par',   \n",
    "    'sup-par',\n",
    "    'supra-marg',\n",
    "    'temp-pole', # TEMPORAL LOBE\n",
    "    'mid-temp',\n",
    "    'sup-temp',\n",
    "    'inf-temp',\n",
    "    'parahip',               \n",
    "    'R-Hip',\n",
    "    'L-Hip',\n",
    "    'R-Amyg',\n",
    "    'L-Amyg',\n",
    "    'entorhinal',\n",
    "    'bankssts',\n",
    "    'fusiform', # OCCIPITAL LOBE                \n",
    "    'lingual']\n",
    "    # 'Right-Inf-Lat-Vent', # OTHER\n",
    "    # 'Right-Cerebral-White-Matter',\n",
    "    # 'Left-Cerebral-White-Matter',\n",
    "    # 'Right-choroid-plexus',\n",
    "    # 'Right-Putamen',\n",
    "    # 'Right-VentralDC']\n",
    "# sx_list = ['lex',\n",
    "#            'lhx',\n",
    "#            'lnx',\n",
    "#            'lfx',\n",
    "#            'ltx',\n",
    "#            'lmx',\n",
    "#            'lud',\n",
    "#            'lup',\n",
    "#            'lld',\n",
    "#            'llp',\n",
    "#            'rex',\n",
    "#            'rhx',\n",
    "#            'rnx',\n",
    "#            'rfx',\n",
    "#            'rtx',\n",
    "#            'rmx',\n",
    "#            'rud',\n",
    "#            'rup',\n",
    "#            'rld',\n",
    "#            'rlp',\n",
    "#            'brx',\n",
    "#            'fax',\n",
    "#            'oax',\n",
    "#            'qcx']\n",
    "sx_list = ['lhx','lup','lud','rhx','rup','rud']\n",
    "mx_list = ['2']\n",
    "# mx_list = ['1','2','3']\n",
    "perdur_input = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82615c75-a765-4453-847f-5c9a10d3477a",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52e545f1-2cd5-40d4-845a-9fe80791e16b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#LINELENGTH MEAN DIFFERENCE BEFORE AND AFTER SYMPTOM ONSET \n",
    "\n",
    "def sem_w8s(LL,at_onset,before_onset,after_onset):\n",
    "    row_num = np.shape(LL)[0]\n",
    "    LL_meandiff = np.empty(row_num,)\n",
    "    for row in range(0,row_num-1): #for each channel in LL   \n",
    "         LL_meandiff[row] = np.mean(LL[row,int(at_onset):int(after_onset)]) - np.mean(LL[row,int(before_onset):int(at_onset)])\n",
    "    return LL_meandiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f14ce657-1f47-44f7-923c-42c795e62dc0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#LINELENGTH TRANSFORM\n",
    "\n",
    "def ll_transform(llw,fs,d,bl_start,bl_stop):    \n",
    "    if bl_start == 0:\n",
    "        sample_bl_start = 0\n",
    "    elif bl_start > 0:\n",
    "        sample_bl_start = (fs*bl_start)[0] #0 because it's python not matlab\n",
    "    sample_bl_end = (fs*bl_stop)[0]-1\n",
    "    \n",
    "    L = int(np.round(llw * fs) - 1) # number of samples to calculate line length\n",
    "    \n",
    "    col_len = np.shape(d)[1]-L\n",
    "    \n",
    "    LL = np.empty([np.shape(d)[0],col_len])\n",
    "    \n",
    "    LL[:] = np.NaN        \n",
    "    \n",
    "    for col_1 in range(0,col_len):\n",
    "        LL[:,col_1] = np.sum(np.abs(np.diff(d[:,col_1:col_1+L])),1)\n",
    "\n",
    "\n",
    "    for row_1 in range(0,np.shape(d)[0]):    \n",
    "        LL_nanmean = np.nanmean(LL[row_1,sample_bl_start:sample_bl_end])\n",
    "        LL_nanstd = np.nanstd(LL[row_1,sample_bl_start:sample_bl_end])\n",
    "                                              \n",
    "        LL[row_1,:] = (LL[row_1,:] - LL_nanmean)/LL_nanstd\n",
    "                    \n",
    "    return LL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d561c82e-d149-4138-a9be-23d4ce572b3c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#XLSX --> PANDA DATAFRAME \n",
    "\n",
    "def open_xl(xl_name): \n",
    "    \n",
    "    df = pd.read_excel(xl_name, index_col=0, engine='openpyxl')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbc92d79-bddb-4528-8d97-ba0717d4b31c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#FILTER PPEEG TO PREPARE FOR LINELENGTH TRANSFORM\n",
    "\n",
    "def filt(d,fs):\n",
    "    d_t = d.transpose()\n",
    "    \n",
    "    butter_array = np.array([1,(round(fs[0]/2)-1)])\n",
    "    b,a = butter(2,butter_array/(fs[0]/2),btype='bandpass',output='ba')\n",
    "    \n",
    "    filt_d = filtfilt(b,a,d_t,axis=0,padtype='odd',padlen=3*(max(len(b),len(a))-1)).transpose()\n",
    "\n",
    "    return filt_d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40c88715-9b46-4a74-8dcb-03f73c084631",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#LOAD MAT FILES \n",
    "\n",
    "def load_elecs(pt_path):\n",
    "                \n",
    "    #load anatomy and electrode matrix\n",
    "    os.chdir(pt_path + 'Imaging/elecs')\n",
    "    e_mat = loadmat('clinical_elecs_all.mat')\n",
    "    anat = e_mat['anatomy'][:,3]\n",
    "    \n",
    "    em = e_mat['elecmatrix']\n",
    "    \n",
    "    em_len = np.shape(em)[0]\n",
    "    anat_len = np.shape(anat)[0]\n",
    "\n",
    "    #delete excess rows in elecmatrix and anatomy\n",
    "    if np.shape(em)[0] < np.shape(anat)[0]:\n",
    "        anat = np.delete(anat,[em_len,anat_len-1])        \n",
    "    elif np.shape(em)[0] > np.shape(anat)[0]:\n",
    "        em = np.delete(em,[anat_len,em_len-1]) \n",
    "\n",
    "    return anat,em"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9e2c6ac-8c03-4760-9ef2-9ae748e4d5c0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#LOAD OPSCEA PARAMETERS \n",
    "\n",
    "def get_params(df_params,pt):\n",
    "    params_bl_start = df_params.loc[pt]['BLstart']\n",
    "    params_bl_stop = df_params.loc[pt]['BLstop']\n",
    "    params_llw = df_params.loc[pt]['llw']\n",
    "\n",
    "    return params_bl_start, params_bl_stop, params_llw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d921d6b3-d7b7-4a04-9129-24b008139d9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#LOAD PATIENT AND SEIZURE NAMES AND LATERALITY\n",
    "\n",
    "def get_ptsz(avg_change_path): #Load list of patient and seizure names\n",
    "    os.chdir(avg_change_path)\n",
    "    \n",
    "    df_params = open_xl('OPSCEAparams.xlsx') # Ndimensions and params_list\n",
    "\n",
    "    with open('sz_name_list.csv','r') as sz_names:\n",
    "        sz_names_list = list(csv.reader(sz_names))\n",
    "        sz_rows = np.size(sz_names_list,0) #find row num \n",
    "        pt_data = []\n",
    "        sz_data= []\n",
    "        direction_data = []\n",
    "        for r in range(0,sz_rows):  #collect symptom data for specfic seizure in list\n",
    "            pt_data.append(sz_names_list[r][0]) \n",
    "            sz_data.append(sz_names_list[r][1]) \n",
    "            direction_data.append(sz_names_list[r][2])\n",
    "    return pt_data, sz_data, direction_data, df_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cc9cd3-5a37-4f35-89f9-2b70ceeb1375",
   "metadata": {
    "tags": []
   },
   "source": [
    "## For loop through patients in list matching seizure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f055f770-bc2f-4039-8203-03c0cf496908",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EC91_03\n",
      "lhx   2\n",
      "lup   2\n",
      "lud   2\n",
      "rhx   2\n",
      "rup   2\n",
      "rud   2\n",
      "EC96_01\n",
      "lhx   2\n",
      "lup   2\n",
      "lud   2\n",
      "rhx   2\n",
      "rup   2\n",
      "rud   2\n",
      "EC107_01\n",
      "lhx   2\n",
      "lup   2\n",
      "lud   2\n",
      "rhx   2\n",
      "rup   2\n",
      "rud   2\n",
      "EC133_03\n",
      "lhx   2\n",
      "lup   2\n",
      "lud   2\n",
      "rhx   2\n",
      "rup   2\n",
      "rud   2\n",
      "EC166_01\n",
      "lhx   2\n",
      "lup   2\n",
      "lud   2\n",
      "rhx   2\n",
      "rup   2\n",
      "rud   2\n",
      "EC228_03\n",
      "lhx   2\n",
      "lup   2\n",
      "lud   2\n",
      "rhx   2\n",
      "rup   2\n",
      "rud   2\n",
      "EC229_02\n",
      "lhx   2\n",
      "lup   2\n",
      "lud   2\n",
      "rhx   2\n",
      "rup   2\n",
      "rud   2\n"
     ]
    }
   ],
   "source": [
    "# def neurosem(sx_input,mx_input,perdur_input,pt_data,sz_data,df_params,workbook):\n",
    "opscea_path = '/Users/nataliasucher/Desktop/UCSF/Coding/OPSCEA/'\n",
    "\n",
    "avg_change_path = opscea_path+'OPSCEADATA/avg_change_folders/'\n",
    "\n",
    "pt_data,sz_data,direction_data,df_params = get_ptsz(avg_change_path) #Ehsan\n",
    "\n",
    "# create xlsx workbook \n",
    "sign_workbook = xlsxwriter.Workbook(opscea_path+'sign_change_LL.xlsx')\n",
    "em_workbook = xlsxwriter.Workbook(opscea_path+'em_LL.xlsx')\n",
    "\n",
    "#For loop through patients\n",
    "for i in range(len(pt_data)):  #Ehsan\n",
    "    pt_i = pt_data[i]          #Ehsan\n",
    "    sz_name = sz_data[i]       #Ehsan\n",
    "    direction = direction_data[i]\n",
    "\n",
    "    pt_path = avg_change_path + pt_i + '/'\n",
    "    os.chdir(pt_path)\n",
    "    pt_dir = os.listdir(pt_path)\n",
    "\n",
    "    for sz_name in sz_data: \n",
    "\n",
    "        if sz_name in pt_dir: #patients in list matching seizure\n",
    "            print(sz_name)\n",
    "            # PARAMS\n",
    "            blstart, blstop, llw = get_params(df_params,pt_i) # 2 = params_llw\n",
    "\n",
    "            # ANAT \n",
    "            anat,em = load_elecs(pt_path)\n",
    "            \n",
    "            emnan = np.isnan(em)\n",
    "            em[emnan] = 0;\n",
    "\n",
    "            # SEMIOLOGY\n",
    "            sz_path = pt_path + sz_data[i]\n",
    "            os.chdir(sz_path)\n",
    "\n",
    "            sz_mat = loadmat(sz_name +'.mat') #load frame speed and ppEEG\n",
    "            fs = sz_mat['fs'].flatten()\n",
    "            d = sz_mat['ppEEG'][0:np.shape(anat)[0],:]\n",
    "\n",
    "            badch_mat = loadmat(sz_name + '_badch.mat')\n",
    "            badch = badch_mat['bad_chs']\n",
    "            badch = np.delete(badch,range(np.shape(anat)[0],np.shape(badch)[0]),0)\n",
    "            \n",
    "            for a_i in range(0,np.shape(anat)[0]):\n",
    "                if np.size(anat[a_i]) > 0: \n",
    "                    if anat[a_i][0] not in neuroanat_list:\n",
    "                        badch[a_i][0] = 1 #prepare for anatomy not in neuroanat list to be deleted in d and anat\n",
    "\n",
    "            bad_logical = np.any(badch,1)\n",
    "            d = d[~bad_logical,:]\n",
    "            anat = anat[~bad_logical]\n",
    "            em = em[~bad_logical,:]\n",
    "\n",
    "            sx_count = 0\n",
    "            for sx_input in sx_list:\n",
    "                sx_count += 1\n",
    "                for mx_input in mx_list:\n",
    "                    print(sx_input,' ',mx_input)\n",
    "\n",
    "#                     XLSX\n",
    "\n",
    "                    sign_worksheet_name = sx_input+' '+mx_input\n",
    "                    em_worksheet_name = sx_input+' '+mx_input\n",
    "\n",
    "                    if i == 0:\n",
    "                        # add 1 xlsx worksheet per symptom/mode\n",
    "                        sign_worksheet = sign_workbook.add_worksheet(sign_worksheet_name) \n",
    "                        # sign_worksheet.write(0,0,sign_worksheet_name) #label symptom \n",
    "                        sign_worksheet.write(0, i, direction_data[i]) #write laterality of onset\n",
    "                        sign_worksheet.write(1, i, sz_data[i]) #write patient seizure name\n",
    "                        \n",
    "                        em_worksheet = em_workbook.add_worksheet(em_worksheet_name) \n",
    "                        for each_col in range(0,np.shape(em)[1]):\n",
    "                            if (each_col % 3) == 0:\n",
    "                                em_worksheet.write(0, 3*i+each_col, direction_data[i]) #write laterality of onset\n",
    "                                em_worksheet.write(1, 3*i+each_col, sz_data[i]) #write patient seizure name        \n",
    "                        \n",
    "                    elif i > 0:\n",
    "                        sign_worksheet = sign_workbook.get_worksheet_by_name(sign_worksheet_name)\n",
    "                        sign_worksheet.write(0, i, direction_data[i]) #write laterality of onset\n",
    "                        sign_worksheet.write(1, i, sz_data[i]) #write patient seizure name        \n",
    "                        \n",
    "                        em_worksheet = em_workbook.get_worksheet_by_name(em_worksheet_name) \n",
    "                        for each_col in range(0,np.shape(em)[1]):\n",
    "                            # em_worksheet.write(0, 3*i+each_col, direction_data[i]) #write laterality of onset\n",
    "                            # em_worksheet.write(1, 3*i+each_col, sz_data[i]) #write patient seizure name        \n",
    "                            if (each_col % 3) == 0:\n",
    "                                em_worksheet.write(0, 3*i+each_col, direction_data[i]) #write laterality of onset\n",
    "                                em_worksheet.write(1, 3*i+each_col, sz_data[i]) #write patient seizure name        \n",
    "\n",
    "\n",
    "                    sx_vec = pd.read_csv(sz_name + '_mat.csv',usecols = [sx_input]).values.tolist() #load semiology matrix .csv             #WANT TO JUST LOAD 1 COLUMN SX_INPUT            \n",
    "\n",
    "                    if np.float64(mx_input) in sx_vec:\n",
    "                        \n",
    "                        filt_d = filt(d,fs) #Filter out < 1 Hz (and up to nyquist)\n",
    "\n",
    "                        LL = ll_transform(llw,fs,filt_d,blstart,blstop) \n",
    "\n",
    "                        at_onset = np.round(((sx_vec.index(np.float64(mx_input)))/5) * fs)\n",
    "                        before_onset = np.round(((sx_vec.index(np.float64(mx_input))/5) - float(perdur_input)) * fs)\n",
    "                        after_onset = np.round(((sx_vec.index(np.float64(mx_input))/5) + float(perdur_input)) * fs)\n",
    "\n",
    "                        LL_meandiff = sem_w8s(LL,at_onset,before_onset,after_onset)\n",
    "                                                \n",
    "                        for each_row in range(0,LL_meandiff.size):\n",
    "                            sign_worksheet.write(each_row+2,i,LL_meandiff.item(each_row))\n",
    "                            \n",
    "                            for each_col in range(0,np.shape(em)[1]):\n",
    "                                em_worksheet.write(each_row+2,3*i+each_col,em[each_row][each_col])\n",
    "            \n",
    "sign_workbook.close()\n",
    "em_workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5265da9-8030-4924-b568-a8e0c7b1079a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tstat, pval = ttest_1samp([-33.00863798812543, -7.4380449766326855],0)\n",
    "# print(pval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9a96ea-283c-407f-9136-410f5094ac0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
